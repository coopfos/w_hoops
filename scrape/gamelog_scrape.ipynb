{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1: imports\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# cell 2: config (EDIT THESE)\n",
    "CSV_PATH   = \"/path/to/your/teams.csv\"   # <- path to your CSV with 'link' column\n",
    "OUTPUT_DIR = \"/path/to/output/folder\"    # <- folder where individual CSVs will be saved\n",
    "\n",
    "REQUESTS_PER_MIN = 6\n",
    "DELAY_SECONDS = math.ceil(60 / REQUESTS_PER_MIN)  # ~10s between requests\n",
    "BASE_URL = \"https://www.sports-reference.com/cbb/schools/{teamcode}/women/2025-gamelogs.html\"\n",
    "TABLE_ID = \"team_game_log\"  # sports-ref's table id\n",
    "\n",
    "# cell 3: helper functions\n",
    "\n",
    "def init_driver(headless=True):\n",
    "    \"\"\"Start a Chrome webdriver (works well in most notebook setups).\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),\n",
    "                              options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def safe_filename(name: str) -> str:\n",
    "    \"\"\"Create a filesystem-safe filename from a team code or school name.\"\"\"\n",
    "    keep = \"-_.() \"\n",
    "    name = \"\".join(c for c in name if c.isalnum() or c in keep)\n",
    "    return name.replace(\" \", \"_\").lower()\n",
    "\n",
    "# cell 4: core scraping logic\n",
    "\n",
    "def scrape_team_gamelog(driver, team_code: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Load the team game log page for a given team code and return the table as a DataFrame.\n",
    "    Returns None if table not found or some error occurs.\n",
    "    \"\"\"\n",
    "    url = BASE_URL.format(teamcode=team_code)\n",
    "    print(f\"Fetching {url}\")\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # wait for the table to be present in DOM\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.ID, TABLE_ID))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  ! Timed out waiting for table for {team_code}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # sports-reference often puts tables inside HTML comments; pandas.read_html handles that\n",
    "    html = driver.page_source\n",
    "\n",
    "    try:\n",
    "        tables = pd.read_html(html, attrs={\"id\": TABLE_ID})\n",
    "        if not tables:\n",
    "            print(f\"  ! No table parsed for {team_code}\")\n",
    "            return None\n",
    "        df = tables[0]\n",
    "        return df\n",
    "    except ValueError:\n",
    "        print(f\"  ! read_html could not find table for {team_code}\")\n",
    "        return None\n",
    "    \n",
    "    # cell 5: driver loop\n",
    "\n",
    "def run_scrape(csv_path: str, output_dir: str,\n",
    "               start_idx: int = 0, end_idx: int | None = None,\n",
    "               headless: bool = True):\n",
    "    \"\"\"\n",
    "    Iterate over team codes in the CSV and save each #team_game_log table as its own CSV.\n",
    "\n",
    "    CSV is expected to contain a column named 'link' with the team codes\n",
    "    (e.g. 'alabama-am', 'albany-ny').\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    teams = pd.read_csv(csv_path)\n",
    "    if \"link\" not in teams.columns:\n",
    "        raise ValueError(\"CSV must contain a 'link' column with team codes.\")\n",
    "\n",
    "    # optional slice of rows (for resuming)\n",
    "    if end_idx is None:\n",
    "        subset = teams.iloc[start_idx:]\n",
    "    else:\n",
    "        subset = teams.iloc[start_idx:end_idx]\n",
    "\n",
    "    driver = init_driver(headless=headless)\n",
    "\n",
    "    try:\n",
    "        for idx, row in subset.iterrows():\n",
    "            team_code = str(row[\"link\"]).strip()\n",
    "\n",
    "            # skip missing/blank codes\n",
    "            if not team_code or team_code.lower() == \"nan\":\n",
    "                print(f\"Skipping row {idx}: empty team code\")\n",
    "                continue\n",
    "\n",
    "            filename = safe_filename(team_code) + \".csv\"\n",
    "            out_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            # skip if already scraped\n",
    "            if os.path.exists(out_path):\n",
    "                print(f\"Already exists, skipping: {out_path}\")\n",
    "                continue\n",
    "\n",
    "            df = scrape_team_gamelog(driver, team_code)\n",
    "            if df is not None and not df.empty:\n",
    "                df.to_csv(out_path, index=False)\n",
    "                print(f\"  -> Saved {out_path}\")\n",
    "            else:\n",
    "                print(f\"  ! No data for {team_code}\")\n",
    "\n",
    "            # rate limiting: ~6 requests per minute\n",
    "            print(f\"Sleeping {DELAY_SECONDS} seconds for rate limit...\")\n",
    "            time.sleep(DELAY_SECONDS)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6: run it\n",
    "run_scrape(CSV_PATH, OUTPUT_DIR, start_idx=0, end_idx=None, headless=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
